#LyX 1.4.1 created this file. For more info see http://www.lyx.org/
\lyxformat 245
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\end_preamble
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize 12
\spacing single
\papersize default
\use_geometry false
\use_amsmath 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language swedish
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Title
Database Management for a Trace Oriented Debugger - Scaling up
\end_layout

\begin_layout Author
Guillaume Pothier
\end_layout

\begin_layout Standard
\begin_inset LatexCommand \tableofcontents{}

\end_inset


\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
In step #2 we presented benchmarks of three types of database backends for
 TOD, our trace-oriented debugger: 
\end_layout

\begin_layout Itemize
Relational, with PostgreSQL and Oracle 10g.
 These provided a throughput of less than 1.000 events/s.
 
\end_layout

\begin_layout Itemize
Generic, with Berkeley DB Java Edition.
 The throughput was almost 10.000 events/s.
 
\end_layout

\begin_layout Itemize
In order to obtain an upper bound on the efficiency we also implemented
 a raw backend that only stores events and doesn't allow queries.
 It is able to handle between 500.000 and 1.000.000 events/s.
 
\end_layout

\begin_layout Standard
In this phase of the project we strive to support at least 100.000 events/s
 so both relational and generic backends have to be ruled out.
 The only remaining possibility is to implement a custom backend, leveraging
 the highly constrained nature of our data and queries.
 
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
This document is divided into two parts: in section 
\begin_inset LatexCommand \ref{sec:Indexing-schemes}

\end_inset

 we devise efficient indexing schemes to speed up our queries.
 Then section 
\begin_inset LatexCommand \ref{sec:grid}

\end_inset

 shows how our problem is amenable to parallelization, and in particular
 that we can scale up quite linearly with respect to the number of nodes.
 
\end_layout

\begin_layout Section
Indexing schemes
\begin_inset LatexCommand \label{sec:Indexing-schemes}

\end_inset

 
\end_layout

\begin_layout Standard
In this section we propose indexing schemes especially crafted for our highly
 constrained data.
 Each of the following subsections focus on one of the three main types
 of queries presented in earlier documents: generic filtering, statistics
 and control flow.
\end_layout

\begin_layout Subsection
Generic filtering 
\end_layout

\begin_layout Standard
Filtering queries return a cursor that can be used to iterate in timestamp
 order over a set of events meeting a particular condition.
 The filtering condition is a boolean combination of 
\begin_inset Formula $f=C$
\end_inset

 comparisons, where 
\begin_inset Formula $f$
\end_inset

 is a field of the event and 
\begin_inset Formula $C$
\end_inset

 is a constant.
 
\end_layout

\begin_layout Standard
Two important specificities of our application should be noted: 
\end_layout

\begin_layout Itemize
Events arrive almost
\begin_inset Foot
status collapsed

\begin_layout Standard
Some events might arrive out of order because of timing inaccuracies, but
 by a small amount.
 Reordering them is very cheap as only the last few events must be taken
 into account.
 From here on we assume that the events have been reordered before they
 reach the backend.
\end_layout

\end_inset

 ordered by timestamp, and for each thread exactly ordered by serial number.
 
\end_layout

\begin_layout Itemize
Events are never deleted from the database.
 As a corollary, there is no reason for a given field value to disappear.
 
\end_layout

\begin_layout Standard
We can leverage these characteristics to implement a fairly efficient indexing
 scheme in which matching events are found without ever accessing the event
 records themselves, relying solely on indexes.
 The remaining of this section describes the n-ary merge join algorithm
 used to find matching events and discusses its I/O and space efficiency.
 
\end_layout

\begin_layout Subsubsection
N-ary merge join
\begin_inset Foot
status collapsed

\begin_layout Standard
We named this algorithm after the well known sort-merge join used by many
 database management systems.
 In our application the sort step is not necessary.
\end_layout

\end_inset

 algorithm 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $S=\left\langle s_{1},...,s_{n}\right\rangle $
\end_inset

 be a stream of 
\begin_inset Formula $n$
\end_inset

 heterogeneous tuples where each 
\begin_inset Formula $s_{i}$
\end_inset

 can have a value for certain fields chosen among the set 
\begin_inset Formula $F=\left\{ f_{0},...,f_{k}\right\} $
\end_inset

.
 Let 
\begin_inset Formula $D_{j}$
\end_inset

 be the domain of 
\begin_inset Formula $f_{j}$
\end_inset

, i.e.
 the set of all distinct values that can be taken by 
\begin_inset Formula $f_{j}$
\end_inset

 for any tuple 
\begin_inset Formula $s_{i}$
\end_inset

.
 The 
\begin_inset Formula $f_{0}$
\end_inset

 field is particular:
\end_layout

\begin_layout Itemize
There must exist a complete order on 
\begin_inset Formula $D_{0}$
\end_inset

.
\end_layout

\begin_layout Itemize
Every tuple has at least the field 
\begin_inset Formula $f_{0}$
\end_inset

, and the tuples of 
\begin_inset Formula $S$
\end_inset

 are ordered by their value of 
\begin_inset Formula $f_{0}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We define 
\begin_inset Formula $I_{j}:D_{j}\mapsto(D_{0},\mathbb{N})^{*}$
\end_inset

 the 
\emph on
index
\emph default
 of 
\begin_inset Formula $S$
\end_inset

 on 
\begin_inset Formula $f_{j}$
\end_inset

 as a function that maps any possible value 
\begin_inset Formula $v$
\end_inset

 of 
\begin_inset Formula $f_{j}$
\end_inset

 to a list of pairs of the form 
\begin_inset Formula $(v_{0},i)$
\end_inset

 ordered by 
\begin_inset Formula $v_{0}$
\end_inset

.
 Such a pair appears in an index 
\begin_inset Formula $I_{j}(v)$
\end_inset

 if and only if the tuple 
\begin_inset Formula $s_{i}$
\end_inset

 has 
\begin_inset Formula $v$
\end_inset

 as the value of 
\begin_inset Formula $f_{j}$
\end_inset

 and 
\begin_inset Formula $v_{0}$
\end_inset

 as the value of 
\begin_inset Formula $f_{0}$
\end_inset

.
 Formally:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\forall v\in D_{j},1\leq i\leq n:(v_{0},i)\in I_{j}(v)\Leftrightarrow\exists s_{i}\in S,s_{i}.f_{j}=v\wedge s_{i}.f_{0}=v_{0}\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset

We shall now see how these indexes can be used to find the tuples that match
 a boolean condition on their fields.
\end_layout

\begin_layout Subsubsection*
Single-term conditions
\end_layout

\begin_layout Standard
In the case of a simple 
\begin_inset Formula $f_{j}=C$
\end_inset

 condition we can retrieve matching tuples ordered by 
\begin_inset Formula $f_{0}$
\end_inset

 by obtaining 
\begin_inset Formula $I_{j}(C)$
\end_inset

 and retaining 
\begin_inset Formula $s_{i}$
\end_inset

 for each 
\begin_inset Formula $(v_{0},i)$
\end_inset

 pair.
 
\end_layout

\begin_layout Subsubsection*
Conjunctive conditions
\end_layout

\begin_layout Standard
Let's now consider a conjunctive boolean condition 
\begin_inset Formula $f_{j_{1}}=C_{1}\wedge\ldots\wedge f_{j_{m}}=C_{m}$
\end_inset

.
 The n-ary merge join algorithm permits to identify matching tuples without
 actually accessing them.
 The idea is to obtain all of the 
\begin_inset Formula $I_{j_{l}}(C_{l})$
\end_inset

 and to maintain a pointer to a current 
\begin_inset Formula $(v_{0_{l}},i_{l})$
\end_inset

 for each.
 Then we start a loop in which at every step we check if all of the 
\begin_inset Formula $i_{l}$
\end_inset

 are equal, in which case we add 
\begin_inset Formula $s_{i}$
\end_inset

 to the result, and then advance the pointer of the pair that has the minumum
 value of 
\begin_inset Formula $v_{0}$
\end_inset

.
 If multiple pairs share the minimum value of 
\begin_inset Formula $v_{0}$
\end_inset

 we advance the pointer of any one of them.
 See algorithm 
\begin_inset LatexCommand \ref{alg:merge-join}

\end_inset

 for details.
 It is easy to see that merge select run in linear time with respect to
 the sum of the sizes of the considered indexes.
 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Caption

\noun on
merge
\noun default
-
\noun on
join
\noun default

\begin_inset LatexCommand \label{alg:merge-join}

\end_inset


\end_layout

\begin_layout Standard
merge-join(
\begin_inset Formula $S$
\end_inset

, 
\begin_inset Formula $j_{1}$
\end_inset

,\SpecialChar \ldots{}
,
\begin_inset Formula $j_{m}$
\end_inset

,
\begin_inset Formula $C_{1}$
\end_inset

,\SpecialChar \ldots{}
,
\begin_inset Formula $C_{m}$
\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
begin{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $result\leftarrow\emptyset$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
FOR{
\end_layout

\end_inset


\begin_inset Formula $l=1$
\end_inset

 to 
\begin_inset Formula $m$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $index[l]\leftarrow I_{j_{l}}(C_{l})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $pos[l]\leftarrow1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDFOR
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
WHILE{
\end_layout

\end_inset

there are more elements
\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $match\leftarrow true$
\end_inset

, 
\begin_inset Formula $refI\leftarrow-1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $minL\leftarrow-1$
\end_inset

, 
\begin_inset Formula $minV0\leftarrow+\infty$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
FOR{
\end_layout

\end_inset


\begin_inset Formula $l=1$
\end_inset

 to 
\begin_inset Formula $m$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $currentI\leftarrow index[l][pos[l]].i$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $currentV0\leftarrow index[l][pos[l]].v0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
IF{
\end_layout

\end_inset


\begin_inset Formula $refI=-1$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $refI\leftarrow currentI$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ELSIF{
\end_layout

\end_inset


\begin_inset Formula $currentI\neq refI$
\end_inset

 
\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $match\leftarrow false$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDIF
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
IF{
\end_layout

\end_inset


\begin_inset Formula $currentV0<minV0$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $minV0\leftarrow currentV0$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $minL\leftarrow l$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDIF
\end_layout

\begin_layout Standard


\backslash
ENDFOR
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
IF{
\end_layout

\end_inset


\begin_inset Formula $match$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $result\leftarrow result\cup\{ s_{refI}\}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDIF
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $pos[minL]\leftarrow pos[minL]+1$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDWHILE
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard

%
\backslash
RETURN
\end_layout

\end_inset

 
\begin_inset Formula $result$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Generic boolean conditions
\end_layout

\begin_layout Standard
We can generalize to any compound boolean condition:
\end_layout

\begin_layout Enumerate
Convert the condition to its Conjunctive Normal Form.
\end_layout

\begin_layout Enumerate
Apply merge join to each conjunction.
\end_layout

\begin_layout Enumerate
Perform a merge (like in merge sort) of the results.
 
\end_layout

\begin_layout Standard
Thus the cost remains linear with respect to the sum of the sizes of the
 considered indexes.
\end_layout

\begin_layout Subsubsection
I/O efficiency of queries
\end_layout

\begin_layout Standard
In this section we compare the I/O costs of the indexed and indexless approaches.
 In our application 
\begin_inset Formula $S$
\end_inset

 is quite naturally the stream of recorded events and 
\begin_inset Formula $f_{0}$
\end_inset

 is the timestamp field.
 Tuples and index entries are stored on hard disk in pages of length 
\begin_inset Formula $P$
\end_inset

; the entries for any given index are stored together in the same pages.
 Let's call 
\begin_inset Formula $tsize$
\end_inset

 the average size of a tuple and 
\begin_inset Formula $isize$
\end_inset

 the size of a 
\begin_inset Formula $(v_{0},i)$
\end_inset

 index entry.
\end_layout

\begin_layout Subsubsection*
Cost of the indexed approach
\end_layout

\begin_layout Standard
We consider a compound boolean condition where terms are of the form 
\begin_inset Formula $f_{j_{l}}=C_{l}$
\end_inset

 for 
\begin_inset Formula $1\leq l\leq m$
\end_inset

.
 We don't care about the actual boolean operators between the terms as they
 have no impact on the I/O cost (merge joins and merges can be pipelined).
\end_layout

\begin_layout Standard
The cost of the indexed approach is determined as follows.
 We determine the number of index pages that must be read:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
N=\frac{isize}{P}\cdot\sum_{l=1}^{m}\left|I_{l}(X)\right|\]

\end_inset


\end_layout

\begin_layout Standard
Then we determine the number of tuple pages that must be read, assuming
 an even distribution of matches in the tuple stream:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
M=min\left(\left|result\right|,\frac{tsize}{P}\cdot\left|S\right|\right)\]

\end_inset


\end_layout

\begin_layout Standard
The total I/O cost of the query is 
\begin_inset Formula $N+M$
\end_inset

, as we don't write the results to disk but instead stream them to the client.
\end_layout

\begin_layout Subsubsection*
Numerical estimation
\end_layout

\begin_layout Standard
The average size of a tuple in 
\begin_inset Formula $S$
\end_inset

 is 
\begin_inset Formula $tsize=42$
\end_inset

 bytes
\begin_inset Foot
status collapsed

\begin_layout Standard
We derive this figure from the results of the benchmarks presented in the
 previous deliverable.
\end_layout

\end_inset

 and the size of a 
\begin_inset Formula $(v_{0},i)$
\end_inset

 pair is 
\begin_inset Formula $isize=16$
\end_inset

 bytes
\begin_inset Foot
status collapsed

\begin_layout Standard
Two 64 bits integers
\end_layout

\end_inset

.
 Unfortunately we do not have statistics of actual event streams and indexes
 generated by real world programs.
 However it is possible to make a rough estimation of a simple case.
\end_layout

\begin_layout Standard
Let's consider two fields 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $f_{2}$
\end_inset

, which could be FieldId and ObjectId for instance, and the request 
\begin_inset Formula $f_{1}=X\wedge f_{2}=Y$
\end_inset

.
 There are 
\begin_inset Formula $\left|S\right|=10,000,000$
\end_inset

 events, of which 10% have a value for 
\begin_inset Formula $f_{1}$
\end_inset

 and 50% have a value for 
\begin_inset Formula $f_{2}$
\end_inset

.
 Additionally we have 
\begin_inset Formula $\left|D_{1}\right|=100$
\end_inset

 distinct values of 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $\left|D_{2}\right|=1,000$
\end_inset

 distinct values for 
\begin_inset Formula $f_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Assuming a uniform distribution of the values of 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $f_{2}$
\end_inset

 in the event stream, we obtain:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{eqnarray*}
\left|I_{1}(X)\right| & = & \frac{10}{100}\cdot\frac{1}{\left|D_{1}\right|}\cdot\left|S\right|=10,000\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \[
\left|I_{2}(Y)\right|=\frac{50}{100}\cdot\frac{1}{\left|D_{2}\right|}\cdot\left|S\right|=5,000\]

\end_inset


\end_layout

\begin_layout Standard
Further assuming that 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $f_{2}$
\end_inset

 are independant, the number of matching tuples would be: 
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\left|result\right|=\left(\frac{10}{100}\cdot\frac{1}{\left|D_{1}\right|}\right)\cdot\left(\frac{50}{100}\cdot\frac{1}{\left|D_{2}\right|}\right)\cdot\left|S\right|=5\]

\end_inset


\end_layout

\begin_layout Standard
If the page size is 
\begin_inset Formula $P=4096$
\end_inset

 we obtain a total number of pages reads of:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\left\lceil \frac{16}{4096}\cdot(10,000+5,000)+5\right\rceil =64\]

\end_inset


\end_layout

\begin_layout Standard
Assuming a rather conservative page access time of 20ms, the query would
 execute in 1.26s.
\begin_inset Foot
status collapsed

\begin_layout Standard
A page access time of 20ms means a throughput of around 200KB/s.
 We know that for sequential accesses we can achieve a 20MB/s throughput.
 Real figures are probably in-between.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Cost of the indexless approach
\end_layout

\begin_layout Standard
A brute force approach reading all tuples would require a number of page
 accesses of:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\left\lceil \left|S\right|\cdot\frac{tsize}{P}\right\rceil \approx100,000\]

\end_inset


\end_layout

\begin_layout Standard
With the same 20ms access time the query would execute in 33mn.
\end_layout

\begin_layout Subsubsection
Space requirements and I/O efficiency of index creation
\begin_inset LatexCommand \label{sub:creation-space-io}

\end_inset


\end_layout

\begin_layout Standard
Having showed that our indexing scheme allows for very fast query execution
 it remains to demonstrate that it is feasible to implement it.
 In particular we must show that its space requirements are reasonable and
 that the indexes can be efficiently created.
 
\end_layout

\begin_layout Standard
For each tuple 
\begin_inset Formula $s_{i}$
\end_inset

 that streams into the backend there are at most 
\begin_inset Formula $\left|F\right|-1$
\end_inset

 indexes to update (there is no index on 
\begin_inset Formula $f_{0}$
\end_inset

).
 As tuples arrive ordered by their value of 
\begin_inset Formula $f_{0}$
\end_inset

, updating an index only means appending the pair 
\begin_inset Formula $(s_{i}.f_{0},i)$
\end_inset

, as shown in algorithm 
\begin_inset LatexCommand \ref{alg:update-indexes}

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Caption

\noun on
update-indexes
\noun default

\begin_inset LatexCommand \label{alg:update-indexes}

\end_inset


\end_layout

\begin_layout Standard
update-indexes(
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $s_{i}$
\end_inset

, 
\begin_inset Formula $F=\{ f_{0},\ldots,f_{k}\}$
\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
begin{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
FOR{
\end_layout

\end_inset


\begin_inset Formula $j=1$
\end_inset

 to 
\begin_inset Formula $k$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $I_{j}(s_{i}.f_{j})\leftarrow I_{j}(s_{i}.f_{j})\cup\{(s_{i}.f_{0},i)\}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDFOR
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can consider in a first approximation that TOD uses 6 different fields
 in addition to the timestamp: BehaviorId, FieldId, ObjectId, ThreadId,
 LocalVarId, BytecodeIndex (we will refine this estimation later).
 This means that for each event, which occupies 42 bytes in average, we
 need 
\begin_inset Formula $6\cdot16=96$
\end_inset

 bytes of additional index space.
 
\end_layout

\begin_layout Standard
The Raw storage backend we implemented achieved a throughput 5 to 10 times
 superior to our objective of 100,000 events/s.
 As we are only slightly more than triplicating the amount of data to store,
 we should still be above our objective under one condition: we must be
 efficient on the I/O.
 To that effect we should only write full index pages to the disk, which
 implies that we must have enough RAM to keep the last page of each used
 index in a buffer.
\end_layout

\begin_layout Standard
The number of distinct indexes is:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\sum_{j=1}^{k}\left|D_{j}\right|\]

\end_inset


\end_layout

\begin_layout Standard
Let's try to estimate that quantity.
 BehaviorId, FieldId, LocalVarId and BytecodeIndex only depend on the structure
 of the code, not on the number of events.
 If the debugged program has 10,000 classes, with 100 fields per class,
 100 behaviors per class and 100 local variables per behavior we would have
 the following counts:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="2">
<features islongtable="true">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
field
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $\left|D_{field}\right|$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
BehaviorId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1,000,000
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
FieldId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1,000,000
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
LocalVarId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
100
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
BytecodeIndex
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
65536
\begin_inset Foot
status collapsed

\begin_layout Standard
As per the Java Virtual Machine Specification
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
ThreadId and ObjectId are more difficult to evaluate.
 Their domain can be really huge given that the program can repetitively
 create and destroy objects and threads.
 However, only a fraction of all threads and objects can be in use at any
 given point in time: all live objects must fit within the memory allocated
 to the JVM, all all live threads must be reasonably executable by the CPU.
 Thus, although the backend will not delete information about old entities,
 it is sufficient to have buffer space for the currently used ones.
 Let's then complete our table:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="2">
<features islongtable="true">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
field
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $\left|D'_{field}\right|$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
ThreadId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1,000
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
ObjectId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
10,000,000
\begin_inset Foot
status collapsed

\begin_layout Standard
Estimation based on a JVM heap size of the order of 1GB.
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
Our backend should ideally have access to about 12,000,000 buffer pages.
 Keeping the same 
\begin_inset Formula $P=4096$
\end_inset

 as before this amounts to more than 40GB of RAM, capacity which is currently
 available only on enterprise-class 64 bits machines.
 
\end_layout

\begin_layout Standard
In order to get back to a realistic solution we must cut down the memory
 requirements.
 One possibility would be to have 
\emph on
write
\emph default
 buffer pages smaller than 
\emph on
read
\emph default
 buffer pages.
 For instance if we reduce the write page size to 128 bytes we would need
 1.5GB of RAM, which is a much more reasonable capacity.
 It remains to be seen, however, what would be the I/O throughput in this
 case.
 We cannot provide a theoretical answer for this problem, we must implement
 some benchmarks to sort it out.
\end_layout

\begin_layout Subsubsection
Refining the index structure 
\end_layout

\begin_layout Standard
Several details were omitted in the previous sections, which we will now
 include to our solution.
\end_layout

\begin_layout Subsubsection*
Timing issues
\end_layout

\begin_layout Standard
It is possible for several events of the same thread to share the same timestamp
 value: although timestamps are reported with nanosecond precision, they
 are not actually accurate to the nanosecond.
 Moreover, even if they were, there would still be the possibility of two
 events occurring at less than a nanosecond interval.
\begin_inset Foot
status collapsed

\begin_layout Standard
It is almost impossible for such a situation to occur with the current generatio
n of CPUs: if we take a clock speed of 4GHz it would mean that two events
 would have to be sent in less than 4 clock cycles.
 It might occur in the future if faster chips are produced.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A solution to this problem would be to alter timestamp values so that they
 are indeed distinct for all events of any given thread.
 We can achieve this by shifting them a few bits to the left and use the
 free bits to differentiate events of the same thread that share the same
 timestamp.
 The free bits are those introduced by the shift and those that are not
 used in the original value because of the lack of accuracy.
\end_layout

\begin_layout Standard
The original timestamp value is a 64 bits integer with nanosecond precision.
 The largest duration that can be represented is then 
\begin_inset Formula $2^{64}\cdot10^{-9}$
\end_inset

 seconds, about 584 years.
 Shifting by 8 bits would reduce it to around two years and permit 256 events
 per nanosecond in a single thread, which is more than enough for our purposes.
 
\end_layout

\begin_layout Subsubsection*
Indexing the indexes
\end_layout

\begin_layout Standard
When a client issues a generic filter query it might not need the whole
 result set; it might even not need more than one event.
 Let's recall that a generic filter query returns a cursor that can be used
 by the client to actually retrieve successive matching events.
 The cursor can be moved forward and backward by one event, and can also
 be positioned directly at a specific position given a reference event or
 timestamp.
 In order to efficiently service such requests the indexes themselves must
 be indexed by timestamp.
\end_layout

\begin_layout Standard
Fortunately this additional indexing is relatively cheap as we can use a
 multilevel clustered index.
 Let's call level-0 the index we already described.
 Whenever a level-0 index page is full, we add a 
\begin_inset Formula $(v_{0},pid)$
\end_inset

 entry to a level-1 index, where 
\begin_inset Formula $v_{0}$
\end_inset

 is taken from the first 
\begin_inset Formula $(v_{0},i)$
\end_inset

 pair of the filled level-0 page, and 
\begin_inset Formula $pid$
\end_inset

 is a pointer to that page.
 Level-1 index entries themselves accumulate in pages, and when such a page
 is full we add an entry to a level-2 index, and so on.
 
\end_layout

\begin_layout Standard
A 
\begin_inset Formula $(v_{0},pid)$
\end_inset

 entry occupies 12 bytes, as we need use only 4 bytes for 
\begin_inset Formula $pid$
\end_inset

.
 It can be easily seen that the storage cost of this method is quite low:
 for each 
\begin_inset Formula $P=4096$
\end_inset

 bytes of level-
\begin_inset Formula $i$
\end_inset

 index we generate 12 bytes of level-
\begin_inset Formula $(i+1)$
\end_inset

 index.
 A level-
\begin_inset Formula $(i+1)$
\end_inset

 page if filled for every 
\begin_inset Formula $\left\lceil \frac{4096}{12}\right\rceil =342$
\end_inset

 level-
\begin_inset Formula $i$
\end_inset

 page.
 The number of index levels is logarithmic with respect to the number of
 index entries.
 For instance, an index with 10,000,000 entries would have 
\begin_inset Formula $\left\lceil log_{342}(10,000,000)\right\rceil =3$
\end_inset

 additional index levels.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
Although the storage space cost of this method is very low there is an overhead
 in either I/O or RAM.
 We have already seen in section 
\begin_inset LatexCommand \ref{sub:creation-space-io}

\end_inset

 that the current page of each level-0 index should be kept in RAM.
 With the multilevel index there are two possibilities: 
\end_layout

\begin_layout Itemize
The current page of all the levels above a particular level-0 index can
 be kept in RAM.
 In this case an extra I/O cost is incurred only when an upper level page
 is full: as a level-
\begin_inset Formula $(i+1)$
\end_inset

 page if filled for every 342 level-
\begin_inset Formula $i$
\end_inset

 page, the I/O overhead is negligible.
 On the other hand the RAM requirements are multiplied by the number of
 index levels, which in practice should not be more than 4.
\end_layout

\begin_layout Itemize
Only the current page of the level-0 index can be kept in RAM.
 In this scenario whenever a level-0 page is filled, the current level-1
 page must be read from disk, updated and then written back to disk.
 Overlooking the level-2 page accesses needed every 342 level-0 accesses,
 the amount of page accesses is tripled.
\end_layout

\begin_layout Standard
Any in-between combination of the above is of course possible.
 We are confident that even with the overhead of the multilevel index scheme
 we can attain our goal of handling 100,000 events/s, though benchmarks
 alone can confirm or infirm this conjecture.
 
\end_layout

\begin_layout Standard
Usage of the multilevel index for queries is straightforward and permits
 to locate the event that is closest to a given timestamp in as many page
 reads as there are levels in the index.
\end_layout

\begin_layout Subsubsection*
Choosing the right fields
\end_layout

\begin_layout Standard
The last point we must refine is the choice of the fields on which we construct
 the indexes.
 Let's consider the same simplified model that we considered for our benchmarks,
 which consists of only three kinds of events:
\end_layout

\begin_layout Itemize
Field write (Timestamp, ThreadId, BytecodeIndex, FieldId, Target, Value).
\end_layout

\begin_layout Itemize
Local variable write (Timestamp, ThreadId, BytecodeIndex, VariableId, Value).
\end_layout

\begin_layout Itemize
Behavior enter (Timestamp, ThreadId, BehaviorId, Target, Arguments) and
 exit (Timestamp, ThreadId, BehaviorId, Result).
\end_layout

\begin_layout Standard
Additionally we consider that every event has a virtual field indicating
 its kind.
 We can use our indexing method verbatim for the ThreadId, BytecodeIndex,
 FieldId, VariableId, BehaviorId and Kind fields.
\end_layout

\begin_layout Standard
There is an issue however with the Value, Target, Arguments and Result fields.
 They all refer to Java objects and thus their values are object ids, but
 they have different semantics.
 We saw in section 
\begin_inset LatexCommand \ref{sub:creation-space-io}

\end_inset

 that maintaining an index for an ObjectId field is very expensive in terms
 of memory requirements, so if we create an index for each one of these
 fields our problem becomes intractable.
 On the other hand if we maintain only one global ObjectId index we cannot
 process a query like 
\begin_inset Formula $Kind=FieldWrite\wedge Target=objectX$
\end_inset

 as it would return not only return the field write events whose Target
 is objectX, but also those whose 
\emph on
Value
\emph default
 is objectX.
\end_layout

\begin_layout Standard
Fortunately we can make a small modification to the ObjectId index so that
 such a request would work.
 Instead of storing 
\begin_inset Formula $(v_{0},i)$
\end_inset

 pairs we store 
\begin_inset Formula $(v_{0},i,r)$
\end_inset

 tuples, where 
\begin_inset Formula $r$
\end_inset

 indicates the 
\emph on
role
\emph default
 of the ObjectId value in the event.
 Table 
\begin_inset LatexCommand \ref{tab:ObjectId-roles-encoding}

\end_inset

 shows a possible encoding.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Caption
ObjectId roles encoding
\begin_inset LatexCommand \label{tab:ObjectId-roles-encoding}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="2">
<features islongtable="true">
<column alignment="center" valignment="top" width="0">
<column alignment="left" valignment="top" leftline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $r$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
role
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $-1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Target
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $-2$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Value
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $-3$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Result
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $\geq0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
Arguments, indicating the argument index
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
As a single byte suffices to represent 
\begin_inset Formula $r$
\end_inset

 it is immediate that the cost of this alteration is minimal.
 The merge join algorithm would be slightly modified so that it accepts
 an additional argument giving a condition on 
\begin_inset Formula $r$
\end_inset

 for each occurence of a condition on an ObjectId field, and considers only
 those index entries that match that condition.
 As a corrollary the algorithm could be given multiple ObjectId conditions
 with different conditions on 
\begin_inset Formula $r$
\end_inset

.
\end_layout

\begin_layout Subsection
Statistics 
\end_layout

\begin_layout Subsection
Control flow reconstitution 
\end_layout

\begin_layout Section
Scaling up with a debugging grid
\begin_inset LatexCommand \label{sec:grid}

\end_inset

 
\end_layout

\begin_layout Section
Conclusion
\end_layout

\end_body
\end_document
