#LyX 1.4.1 created this file. For more info see http://www.lyx.org/
\lyxformat 245
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\end_preamble
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize 12
\spacing single
\papersize default
\use_geometry false
\use_amsmath 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language swedish
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Title
Database Management for a Trace Oriented Debugger - Scaling up
\end_layout

\begin_layout Author
Guillaume Pothier
\end_layout

\begin_layout Standard
\begin_inset LatexCommand \tableofcontents{}

\end_inset


\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
In step #2 we presented benchmarks of three types of database backends for
 TOD, our trace-oriented debugger: 
\end_layout

\begin_layout Itemize
Relational, with PostgreSQL and Oracle 10g.
 These provided a throughput of less than 1.000 events/s.
 
\end_layout

\begin_layout Itemize
Generic, with Berkeley DB Java Edition.
 The throughput was almost 10.000 events/s.
 
\end_layout

\begin_layout Itemize
In order to obtain an upper bound on the efficiency we also implemented
 a raw backend that only stores event and doesn't allow queries.
 We were able to handle between 500.000 and 1.000.000 events/s.
 
\end_layout

\begin_layout Standard
As we strive to support at least 100.000 events/s in this phase of the project,
 both relational and generic backends have to be ruled out.
 The only remaining possibility is to implement a custom backend, leveraging
 the highly constrained nature of our data and queries.
 
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
This document is divided into two parts: first we devise efficient indexing
 schemes for generic filtering and statistical queries.
 Next we show how our problem is amenable to parallelization, and that we
 can scale up quite linearly in the number of hosts.
 
\end_layout

\begin_layout Section
Indexing schemes 
\end_layout

\begin_layout Standard
In this section we propose indexing schemes especially crafted for our highly
 constrained data.
 Each of the following subsections focus on one of the three main types
 of queries presented in earlier documents.
 
\end_layout

\begin_layout Subsection
Generic filtering 
\end_layout

\begin_layout Standard
Filtering queries return a cursor that can be used to iterate in timestamp
 order over a set of events meeting a particular condition.
 The filtering condition is a boolean combination of 
\begin_inset Formula $f=C$
\end_inset

 comparisons, where 
\begin_inset Formula $f$
\end_inset

 is a field of the event and 
\begin_inset Formula $C$
\end_inset

 is a constant.
 
\end_layout

\begin_layout Standard
Two important specificities of our application should be noted: 
\end_layout

\begin_layout Itemize
Events arrive almost
\begin_inset Foot
status collapsed

\begin_layout Standard
Some events might arrive out of order because of timing inaccuracies, but
 by a small amount.
 Reordering them is very cheap as only the last few events must be taken
 into account.
 From here on we assume that the reordering step is performed and that events
 actually are ordered by timestamp when they reach the backend.
\end_layout

\end_inset

 ordered by timestamp, and for each thread exactly ordered by serial number.
 
\end_layout

\begin_layout Itemize
Events are never deleted from the database.
 As a corollary, there is no reason for a given ClassId, BehaviorId or any
 of the aforementioned Id values to disappear.
 
\end_layout

\begin_layout Standard
We can leverage these characteristics to implement a fairly efficient indexing
 scheme in which matching events are found without ever accessing the event
 records themselves, relying solely on indexes.
 The remaining of this section describes the merge select algorithm used
 to find matching events and discusses its I/O and space efficiency.
 
\end_layout

\begin_layout Subsubsection
Merge select
\begin_inset Foot
status collapsed

\begin_layout Standard
This algorithm probably already has a name of its own, of which we are not
 aware.
 We called it merge select for its resemblance with merge sort.
\end_layout

\end_inset

 algorithm 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $S=\left[s_{1},s_{2},...,s_{n}\right]$
\end_inset

 be a stream of heterogeneous tuples where each 
\begin_inset Formula $s_{i}$
\end_inset

 has a number of fields chosen among a set of fields 
\begin_inset Formula $F=\left\{ f_{0},...,f_{k}\right\} $
\end_inset

.
 Let 
\begin_inset Formula $D_{j}$
\end_inset

 be the domain of 
\begin_inset Formula $f_{j}$
\end_inset

, i.e.
 the set of all the values that can be taken by 
\begin_inset Formula $f_{j}$
\end_inset

 for any tuple 
\begin_inset Formula $s_{i}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The field 
\begin_inset Formula $f_{0}$
\end_inset

 is particular:
\end_layout

\begin_layout Itemize
There must exist a complete order on 
\begin_inset Formula $D_{0}$
\end_inset

.
\end_layout

\begin_layout Itemize
Every 
\begin_inset Formula $s_{i}$
\end_inset

 has at least the field 
\begin_inset Formula $f_{0}$
\end_inset

, and the 
\begin_inset Formula $s_{i}$
\end_inset

 are ordered by their value of 
\begin_inset Formula $f_{0}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We define 
\begin_inset Formula $I_{j}:D_{j}\mapsto(D_{0},\mathbb{N})^{*}$
\end_inset

 the 
\emph on
index
\emph default
 of 
\begin_inset Formula $S$
\end_inset

 on 
\begin_inset Formula $f_{j}$
\end_inset

 as a function that maps any possible value 
\begin_inset Formula $v$
\end_inset

 of 
\begin_inset Formula $f_{j}$
\end_inset

 to a list of pairs of the form 
\begin_inset Formula $(v_{0},i)$
\end_inset

 ordered by 
\begin_inset Formula $v_{0}$
\end_inset

.
 There is a pair in an index 
\begin_inset Formula $I_{j}(v)$
\end_inset

 for all the tuples 
\begin_inset Formula $s\in S$
\end_inset

 that have 
\begin_inset Formula $v$
\end_inset

 as the value of 
\begin_inset Formula $f_{j}$
\end_inset

 and where 
\begin_inset Formula $v_{0}$
\end_inset

 is the value of 
\begin_inset Formula $s.f_{0}$
\end_inset

.
 Formally:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\forall v\in D_{j},1\leq i\leq n:(v_{0},i)\in I_{j}(v)\Leftrightarrow\exists s\in S,s.f_{j}=v\wedge s.f_{0}=v_{0}\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset

We shall now see how these indexes can be used to select the tuples that
 match a boolean combination of conditions on their fields.
\end_layout

\begin_layout Subsubsection*
Single-term conditions
\end_layout

\begin_layout Standard
In the case of a simple 
\begin_inset Formula $f_{j}=C$
\end_inset

 condition we can retrieve matching tuples ordered by 
\begin_inset Formula $f_{0}$
\end_inset

 by obtaining 
\begin_inset Formula $I_{j}(C)$
\end_inset

 and retaining 
\begin_inset Formula $s_{i}$
\end_inset

 of each 
\begin_inset Formula $(v_{0},i)$
\end_inset

 pair.
 
\end_layout

\begin_layout Subsubsection*
Conjunctive conditions
\end_layout

\begin_layout Standard
Let's now consider a conjunctive boolean condition 
\begin_inset Formula $f_{j_{1}}=C_{1}\wedge\ldots\wedge f_{j_{m}}=C_{m}$
\end_inset

.
 The merge select algorithm permits to obtain the stream of matching tuples
 without actually accessing the tuples.
 The idea is to obtain all of the 
\begin_inset Formula $I_{j_{l}}(C_{l})$
\end_inset

 and to maintain a pointer to a current 
\begin_inset Formula $(v_{0_{l}},i_{l})$
\end_inset

 for each.
 Then we start a loop in which at every step we check if all of the 
\begin_inset Formula $i_{l}$
\end_inset

 are equal, in which case we add 
\begin_inset Formula $s_{i}$
\end_inset

 to the result, and then advance the pointer of the pair that has the minumum
 value of 
\begin_inset Formula $v_{0}$
\end_inset

.
 If multiple pairs share the minimum value of 
\begin_inset Formula $v_{0}$
\end_inset

 we advance the pointer of any one of them.
 See algorithm 
\begin_inset LatexCommand \ref{alg:merge-select}

\end_inset

 for details.
 It is easy to see that merge select run in linear time with respect to
 the sum of the sizes of the considered indexes.
 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Caption

\noun on
merge-select
\noun default

\begin_inset LatexCommand \label{alg:merge-select}

\end_inset


\end_layout

\begin_layout Standard
merge-select(
\begin_inset Formula $S$
\end_inset

, 
\begin_inset Formula $j_{1}$
\end_inset

,\SpecialChar \ldots{}
,
\begin_inset Formula $j_{m}$
\end_inset

,
\begin_inset Formula $C_{1}$
\end_inset

,\SpecialChar \ldots{}
,
\begin_inset Formula $C_{m}$
\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
begin{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $result\leftarrow\emptyset$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
FOR{
\end_layout

\end_inset


\begin_inset Formula $l=1$
\end_inset

 to 
\begin_inset Formula $m$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $index[l]\leftarrow I_{j_{l}}(C_{l})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $pos[l]\leftarrow1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDFOR
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
WHILE{
\end_layout

\end_inset

there are more elements
\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $match\leftarrow true$
\end_inset

, 
\begin_inset Formula $refI\leftarrow-1$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $minL\leftarrow-1$
\end_inset

, 
\begin_inset Formula $minV0\leftarrow+\infty$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
FOR{
\end_layout

\end_inset


\begin_inset Formula $l=1$
\end_inset

 to 
\begin_inset Formula $m$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $currentI\leftarrow index[l][pos[l]].i$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $currentV0\leftarrow index[l][pos[l]].v0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
IF{
\end_layout

\end_inset


\begin_inset Formula $refI=-1$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $refI\leftarrow currentI$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ELSIF{
\end_layout

\end_inset


\begin_inset Formula $currentI\neq refI$
\end_inset

 
\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $match\leftarrow false$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDIF
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
IF{
\end_layout

\end_inset


\begin_inset Formula $currentV0<minV0$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $minV0\leftarrow currentV0$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $minL\leftarrow l$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDIF
\end_layout

\begin_layout Standard


\backslash
ENDFOR
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
IF{
\end_layout

\end_inset


\begin_inset Formula $match$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $result\leftarrow result\cup\{ s_{refI}\}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDIF
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $pos[minL]\leftarrow pos[minL]+1$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDWHILE
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard

%
\backslash
RETURN
\end_layout

\end_inset

 
\begin_inset Formula $result$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Generic boolean conditions
\end_layout

\begin_layout Standard
We can generalize to any compound boolean condition:
\end_layout

\begin_layout Enumerate
Convert the condition to Conjunctive Normal Form.
\end_layout

\begin_layout Enumerate
Apply merge select to each conjunction.
\end_layout

\begin_layout Enumerate
Perform a merge (like in merge sort) of the results.
 
\end_layout

\begin_layout Standard
Thus the cost remains linear with respect to the sum of the sizes of the
 considered indexes.
\end_layout

\begin_layout Subsubsection
I/O efficiency of queries
\end_layout

\begin_layout Standard
In this section we compare the I/O costs of indexed and indexless approaches.
 In our application 
\begin_inset Formula $S$
\end_inset

 is quite naturally the stream of recorded events and 
\begin_inset Formula $f_{0}$
\end_inset

 is the timestamp field.
 Tuples and index pairs are stored on hard disk in pages of length 
\begin_inset Formula $P$
\end_inset

; the pairs for any given index are stored together in the same pages.
 Let's call 
\begin_inset Formula $tsize$
\end_inset

 the average size of a tuple and 
\begin_inset Formula $psize$
\end_inset

 the size of a 
\begin_inset Formula $(v_{0},i)$
\end_inset

 index pair.
\end_layout

\begin_layout Subsubsection*
Cost of the indexed approach
\end_layout

\begin_layout Standard
We consider a compound boolean condition where terms are of the form 
\begin_inset Formula $f_{j_{l}}=C_{l}$
\end_inset

 for 
\begin_inset Formula $1\leq l\leq m$
\end_inset

.
 We don't care about the actual boolean operators between the terms as they
 have no impact on the I/O cost (merge selects and merges can be pipelined).
\end_layout

\begin_layout Standard
The cost of the indexed approach is determined as follows.
 We determine the number of index pages that must be read:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
N=\frac{psize}{P}\cdot\sum_{l=1}^{m}\left|I_{l}(X)\right|\]

\end_inset


\end_layout

\begin_layout Standard
Then we determine the number of tuple pages that must be read, assuming
 an even distribution of matches in the tuple stream:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
M=min\left(\left|result\right|,\frac{tsize}{P}\cdot\left|S\right|\right)\]

\end_inset


\end_layout

\begin_layout Standard
The total I/O cost of the query is 
\begin_inset Formula $N+M$
\end_inset

, as we don't write the results to disk but instead stream them to the client.
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Subsubsection*
Numerical estimation
\end_layout

\begin_layout Standard
The average size of a tuple in 
\begin_inset Formula $S$
\end_inset

 is 
\begin_inset Formula $tsize=42$
\end_inset

 bytes
\begin_inset Foot
status collapsed

\begin_layout Standard
We derive this figure from the results of the benchmarks presented in the
 previous deliverable.
\end_layout

\end_inset

 and the size of a 
\begin_inset Formula $(v_{0},i)$
\end_inset

 pair is 
\begin_inset Formula $psize=16$
\end_inset

 bytes
\begin_inset Foot
status collapsed

\begin_layout Standard
Two 64 bits integers
\end_layout

\end_inset

.
 Unfortunately we do not have statistics of actual event streams and indexes
 generated by real world programs.
 However it is possible to make a rough estimation of a simple case.
\end_layout

\begin_layout Standard
Let's consider two fields 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $f_{2}$
\end_inset

, which could be FieldId and ObjectId for instance, and the request 
\begin_inset Formula $f_{1}=X\wedge f_{2}=Y$
\end_inset

.
 There are 
\begin_inset Formula $\left|S\right|=10,000,000$
\end_inset

 events, of which 10% have a value for 
\begin_inset Formula $f_{1}$
\end_inset

 and 50% have a value for 
\begin_inset Formula $f_{2}$
\end_inset

.
 Additionally we have 
\begin_inset Formula $\left|D_{1}\right|=100$
\end_inset

 distinct values of 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $\left|D_{2}\right|=1,000$
\end_inset

 distinct values for 
\begin_inset Formula $f_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Assuming a uniform distribution of the values of 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $f_{2}$
\end_inset

 in the event stream, we obtain:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{eqnarray*}
\left|I_{1}(X)\right| & = & \frac{10}{100}\cdot\frac{1}{\left|D_{1}\right|}\cdot\left|S\right|=10,000\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \[
\left|I_{2}(Y)\right|=\frac{50}{100}\cdot\frac{1}{\left|D_{2}\right|}\cdot\left|S\right|=5,000\]

\end_inset


\end_layout

\begin_layout Standard
Further assuming that 
\begin_inset Formula $f_{1}$
\end_inset

 and 
\begin_inset Formula $f_{2}$
\end_inset

 are independant, the number of matching tuples would be: 
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\left|result\right|=\left(\frac{10}{100}\cdot\frac{1}{\left|D_{1}\right|}\right)\cdot\left(\frac{50}{100}\cdot\frac{1}{\left|D_{2}\right|}\right)\cdot\left|S\right|=5\]

\end_inset


\end_layout

\begin_layout Standard
If the page size is 
\begin_inset Formula $P=4096$
\end_inset

 we obtain a total number of pages reads of:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\frac{16}{4096}\cdot(10,000+5,000)+5\approx63\]

\end_inset


\end_layout

\begin_layout Standard
Assuming a rather conservative page access time of 20ms, the query would
 execute in 1.26s.
\begin_inset Foot
status collapsed

\begin_layout Standard
A page access time of 20ms means a throughput of around 200KB/s.
 We know that for sequential accesses we can achieve a 20MB/s throughput.
 Real figures are probably in-between.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Cost of the indexless approach
\end_layout

\begin_layout Standard
A brute force approach would have required to read all tuples, requiring
 a number of page accesses of:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\left|S\right|\cdot\frac{tsize}{P}\approx100,000\]

\end_inset


\end_layout

\begin_layout Standard
With the same 20ms access time the query would execute in 33mn.
\end_layout

\begin_layout Subsubsection
Space requirements and I/O efficiency of index creation
\end_layout

\begin_layout Standard
Having showed that our indexing scheme allows for very fast query execution
 it remains to demonstrate that it is feasible to implement it.
 In particular we must show that its space requirements are reasonable and
 that the indexes can be efficiently created.
 
\end_layout

\begin_layout Standard
For each tuple 
\begin_inset Formula $s_{i}$
\end_inset

 that streams into the backend there are at most 
\begin_inset Formula $\left|F\right|-1$
\end_inset

 indexes to update (there is no index on 
\begin_inset Formula $f_{0}$
\end_inset

).
 As tuples arrive ordered by their value of 
\begin_inset Formula $f_{0}$
\end_inset

, updating an index only means appending the pair 
\begin_inset Formula $(s_{i}.f_{0},i)$
\end_inset

, as shown in algorithm 
\begin_inset LatexCommand \ref{alg:update-indexes}

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Caption

\noun on
update-indexes
\noun default

\begin_inset LatexCommand \label{alg:update-indexes}

\end_inset


\end_layout

\begin_layout Standard
update-indexes(
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $s_{i}$
\end_inset

, 
\begin_inset Formula $F=\{ f_{0},\ldots,f_{k}\}$
\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
begin{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
FOR{
\end_layout

\end_inset


\begin_inset Formula $j=1$
\end_inset

 to 
\begin_inset Formula $k$
\end_inset


\begin_inset ERT
status open

\begin_layout Standard

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
STATE
\end_layout

\end_inset

 
\begin_inset Formula $I_{j}(s_{i}.f_{j})\leftarrow I_{j}(s_{i}.f_{j})\cup\{(s_{i}.f_{0},i)\}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
ENDFOR
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Standard


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can consider in a first approximation that TOD uses 6 different fields
 in addition to the timestamp: BehaviorId, FieldId, ObjectId, ThreadId,
 LocalVarId, BytecodeIndex (we will refine this estimation later).
 This means that for each event, which occupies 42 bytes in average, we
 need 
\begin_inset Formula $6\cdot16=96$
\end_inset

 bytes of additional index space.
 
\end_layout

\begin_layout Standard
The Raw storage backend we implemented achieved a throughput 5 to 10 times
 superior to our objective of 100,000 events/s.
 As we are only slightly more than triplicating the amount of data to store,
 we should still be above our objective under one condition: we must be
 efficient on the I/O.
 To that effect we should only write full index pages to the disk, which
 implies that we must have enough RAM to keep the last page of each used
 index in a buffer.
\end_layout

\begin_layout Standard
The number of distinct indexes is:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\sum_{j=1}^{k}\left|D_{j}\right|\]

\end_inset


\end_layout

\begin_layout Standard
Let's try to estimate that quantity.
 BehaviorId, FieldId, LocalVarId and BytecodeIndex only depend on the structure
 of the code, not on the number of events.
 If the debugged program has 10,000 classes, with 100 fields per class,
 100 behaviors per class and 100 local variables per behavior we would have
 the following counts:
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="2">
<features islongtable="true">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
field
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $\left|D_{field}\right|$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
BehaviorId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1,000,000
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
FieldId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1,000,000
\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
LocalVarId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
100
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
BytecodeIndex
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
65536
\begin_inset Foot
status collapsed

\begin_layout Standard
As per the Java Virtual Machine Specifications
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset

ThreadId and ObjectId are more difficult to evaluate.
 Their domain can be really huge given that the program can repetitively
 create and destroy objects and threads.
 However, only a fraction of all threads and objects can be in use at any
 given point in time: all live objects must fit within the memory allocated
 to the JVM, all all live threads must be reasonably executable by the CPU.
 Thus, although the backend will not delete information about old entities,
 it is sufficient to have buffer space for the most recently used ones.
 Let's then complete our table:
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="2">
<features islongtable="true">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
field
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
\begin_inset Formula $\left|D'_{field}\right|$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
ThreadId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
1,000
\end_layout

\end_inset
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
ObjectId
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Standard
10,000,000
\begin_inset Foot
status collapsed

\begin_layout Standard
Estimation based on a JVM heap size of the order of 100MB.
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
Our backend should ideally have access to about 12,000,000 buffer pages.
 Keeping the same 
\begin_inset Formula $P=4096$
\end_inset

 as before this amounts to more than 40GB of RAM, capacity which is currently
 available only on enterprise-class 64 bits machines.
 
\end_layout

\begin_layout Standard
In order to get back to a realistic solution we must cut down the memory
 requirements.
 One possibility would be to have 
\emph on
write
\emph default
 buffer pages smaller than 
\emph on
read
\emph default
 buffer pages.
 For instance if we reduce the write page size to 128 bytes we would need
 1.5GB of RAM, which is a much more reasonable capacity.
 It remains to be seen, however, what would be the I/O throughput in this
 case.
 We cannot provide a theoretical answer for this problem, we must implement
 some benchmarks to sort it out.
\end_layout

\begin_layout Subsubsection
Refining the index structure 
\end_layout

\begin_layout Standard
Several details were omitted in the previous sections, which we will now
 include to our solution.
\end_layout

\begin_layout Subsubsection*
Timing issues
\end_layout

\begin_layout Standard
The timestamps of the events have a limited accuracy: it is possible for
 several events of the same thread to share the same timestamp value.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
A solution to this problem would be to alter timestamp values so that they
 are indeed distinct and increasing for all events of any given thread,
 and that an event that occured after another event of the same thread.
 We can achieve this by shifting them a few bits to the left and use the
 free bits to differentiate events of the same thread that share the same
 timestamp.
 
\end_layout

\begin_layout Standard
The amount of shifting is a tradeoff between the desired duration of the
 debugging session and the expected number of events that can occur during
 a nanosecond.
\end_layout

\begin_layout Standard
The original timestamp value is a 64 bits integer with nanosecond precision.
 The largest duration that can be represented is then 
\begin_inset Formula $2^{64}\cdot10^{-9}$
\end_inset

 seconds, that is about 584 years.
 If we shift left by 8 bits, we could still represent a more than two year
 duration, while allowing for 256 events per nanosecond, which is 
\end_layout

\begin_layout Subsubsection*
Indexing the indexes
\end_layout

\begin_layout Standard
When a client issues a generic filter query
\end_layout

\begin_layout Standard
Let's first observe that the event fields can be divided into two groups:
 
\end_layout

\begin_layout Itemize
ClassId, BehaviorId, FieldId and LocalVarId depend on the structure of the
 debugged program and generally do not depend on the number of generated
 events.
\begin_inset Foot
status collapsed

\begin_layout Standard
A worst case scenario would be a program that continually generates classes,
 loads them and executes some methods in them.
 However, this is a far from common task.
\end_layout

\end_inset

 In other words, once all classes have been loaded, the debugged program
 can run forever without generating any new value for ClassId, for instance.
 Moreover, the value domain of these fields is dense in the sense that if
 there exists a value k for ClassId it means that all values from 1 to k-1
 also exist.
 This is because values for those fields are generated sequentially as classes
 are loaded.
 
\end_layout

\begin_layout Itemize
ObjectId and ThreadId on the other hand might depend on the number of generated
 events: it is not uncommon for a program to repetitively create and destroy
 objects or threads.
 The value domain of these fields are sparse, as opposed to the dense value
 domains of the previous group's fields.
 
\end_layout

\begin_layout Subsection
Statistics 
\end_layout

\begin_layout Subsection
Control flow reconstitution 
\end_layout

\begin_layout Section
Scaling up with a debugging grid 
\end_layout

\begin_layout Section
Conclusion
\end_layout

\end_body
\end_document
